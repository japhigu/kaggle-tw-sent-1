{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goldaw\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\goldaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\goldaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import fastparquet\n",
    "from gensim.models.wrappers import FastText\n",
    "#import gensim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\") \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data from precomputed dataframe\n",
    "pfile = fastparquet.ParquetFile('5col_DFrame.parq') \n",
    "df = pfile.to_pandas() # all columns \n",
    "#df2 = pfile.to_pandas(columns=['floats', 'times']) # pick some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean1</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>wordlist</th>\n",
       "      <th>no_names_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10494</th>\n",
       "      <td>Negative</td>\n",
       "      <td>The question about God and the Veterans. What ...</td>\n",
       "      <td>question god veterans softball gopdebates</td>\n",
       "      <td>[gopdebates]</td>\n",
       "      <td>[question, god, veterans, softball]</td>\n",
       "      <td>question god veterans softball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10495</th>\n",
       "      <td>Negative</td>\n",
       "      <td>I thought #LastComicStanding airs on Wednesday...</td>\n",
       "      <td>thought lastcomicstanding airs wednesday night...</td>\n",
       "      <td>[lastcomicstanding, gopdebates]</td>\n",
       "      <td>[thought, airs, wednesday, nights]</td>\n",
       "      <td>thought airs wednesday nights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10496</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Bingo! Put that in your article!!! #GOPDebates...</td>\n",
       "      <td>bingo put article gopdebates httpstcoxaaqwagf</td>\n",
       "      <td>[gopdebates]</td>\n",
       "      <td>[bingo, put, article]</td>\n",
       "      <td>bingo put article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10497</th>\n",
       "      <td>Negative</td>\n",
       "      <td>RT @RWSurferGirl: Fox is cherry picking the ca...</td>\n",
       "      <td>fox cherry picking candidates jeb softball que...</td>\n",
       "      <td>[gopdebates, gopdebates]</td>\n",
       "      <td>[fox, cherry, picking, candidates, jeb, softba...</td>\n",
       "      <td>fox cherry picking candidates jeb softball que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>Waiting on Trumps answer about God #GOPDebates...</td>\n",
       "      <td>waiting trumps answer god gopdebates aintenoug...</td>\n",
       "      <td>[gopdebates, aintenoughpopcornforthis]</td>\n",
       "      <td>[waiting, trumps, answer, god]</td>\n",
       "      <td>waiting trumps answer god</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text  \\\n",
       "10494  Negative  The question about God and the Veterans. What ...   \n",
       "10495  Negative  I thought #LastComicStanding airs on Wednesday...   \n",
       "10496  Negative  Bingo! Put that in your article!!! #GOPDebates...   \n",
       "10497  Negative  RT @RWSurferGirl: Fox is cherry picking the ca...   \n",
       "10498   Neutral  Waiting on Trumps answer about God #GOPDebates...   \n",
       "\n",
       "                                             text_clean1  \\\n",
       "10494          question god veterans softball gopdebates   \n",
       "10495  thought lastcomicstanding airs wednesday night...   \n",
       "10496      bingo put article gopdebates httpstcoxaaqwagf   \n",
       "10497  fox cherry picking candidates jeb softball que...   \n",
       "10498  waiting trumps answer god gopdebates aintenoug...   \n",
       "\n",
       "                                     hashtags  \\\n",
       "10494                            [gopdebates]   \n",
       "10495         [lastcomicstanding, gopdebates]   \n",
       "10496                            [gopdebates]   \n",
       "10497                [gopdebates, gopdebates]   \n",
       "10498  [gopdebates, aintenoughpopcornforthis]   \n",
       "\n",
       "                                                wordlist  \\\n",
       "10494                [question, god, veterans, softball]   \n",
       "10495                 [thought, airs, wednesday, nights]   \n",
       "10496                              [bingo, put, article]   \n",
       "10497  [fox, cherry, picking, candidates, jeb, softba...   \n",
       "10498                     [waiting, trumps, answer, god]   \n",
       "\n",
       "                                       no_names_hashtags  \n",
       "10494                     question god veterans softball  \n",
       "10495                      thought airs wednesday nights  \n",
       "10496                                  bingo put article  \n",
       "10497  fox cherry picking candidates jeb softball que...  \n",
       "10498                          waiting trumps answer god  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61205"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create fasttext obj\n",
    "fs = FastText()\n",
    "\n",
    "## Create list of all words in our target dataset\n",
    "words = [] \n",
    "for entry in df.wordlist:\n",
    "    for word in entry:\n",
    "        words.append(word)\n",
    "        #word = word.lower()\n",
    "        #i = i+1\n",
    "        #if 1 <= i <= 10:\n",
    "        #    if word in model:\n",
    "        #        model2 = model[word]\n",
    "\n",
    "#distinct words in our dataset        \n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##load the FastText pre-trained vectors from facebook.\n",
    "\n",
    "#this is actually not needed for our task - we do not need the high-dimensional semantic information contained within \n",
    "#the model for the kaggle challenge.\n",
    "\n",
    "#lots of problems loading the dataset through gensim, takes a long time.\n",
    "#using \"words\" list to exclude unneeded words would be a useful extension\n",
    "\n",
    "#model = fs.load_binary_data('wiki.en.bin')\n",
    "#model = fs.load_fasttext_format('wiki.en')\n",
    "model =  fs.load_word2vec_format('wiki.en.vec')\n",
    "#print model.words # list of words in dictionary\n",
    "#print(model['king']) # get the vector of the word 'king'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8592ed92ba49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;31m#             print(word)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-8592ed92ba49>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;31m#             print(word)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\goldaw\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "#stub for a function removing uneeded words from fasttextmodel - unexplored\n",
    "# i = 0\n",
    "# for word in words:\n",
    "#     if (word in model):\n",
    "#         i = i + 1\n",
    "#         if 1 <= i <= 10:\n",
    "#             print(word in model)\n",
    "#             print(word)\n",
    "\n",
    "model2 = {model[word] for word in model if word in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words.remove(\"90\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
