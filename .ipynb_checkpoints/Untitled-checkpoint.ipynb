{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/TIE/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import re\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = 'train_data.csv'\n",
    "def load_data(url=URL):\n",
    "\treturn pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10494</th>\n",
       "      <td>Negative</td>\n",
       "      <td>The question about God and the Veterans. What ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10495</th>\n",
       "      <td>Negative</td>\n",
       "      <td>I thought #LastComicStanding airs on Wednesday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10496</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Bingo! Put that in your article!!! #GOPDebates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10497</th>\n",
       "      <td>Negative</td>\n",
       "      <td>RT @RWSurferGirl: Fox is cherry picking the ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>Waiting on Trumps answer about God #GOPDebates...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text\n",
       "10494  Negative  The question about God and the Veterans. What ...\n",
       "10495  Negative  I thought #LastComicStanding airs on Wednesday...\n",
       "10496  Negative  Bingo! Put that in your article!!! #GOPDebates...\n",
       "10497  Negative  RT @RWSurferGirl: Fox is cherry picking the ca...\n",
       "10498   Neutral  Waiting on Trumps answer about God #GOPDebates..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleantweet(s):\n",
    "\t'''\n",
    "\t:s : string; a tweet\n",
    "\t:return : list; words that don't contain url, @somebody, and in utf-8 and lower case\n",
    "\t'''\n",
    "\ts = re.sub(cleantweet.pattern, '', s, 1)\n",
    "\tremove_punctuation_map = dict.fromkeys(map(ord, string.punctuation))\n",
    "\t# actually remove the punctutation\n",
    "\ts = s.translate(remove_punctuation_map)\n",
    "\t# tokenize tweet into sentences\n",
    "\tsents = sent_tokenize(s)\n",
    "# tokenize sentences into list of words\n",
    "\twords = [word_tokenize(s) for s in sents]\n",
    "# NO IDEA\n",
    "\twords = [e for sent in words for e in sent]\n",
    "\treturn [cleantweet.stemmer.stem(e.lower()) for e in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Removing the morphological and inflexional endings from words in English.\n",
    "cleantweet.stemmer = PorterStemmer()\n",
    "cleantweet.pattern = re.compile(r'@\\w+')\n",
    "df.loc[:,'text'] = df.loc[:,'text'].map(cleantweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>[rt, how, did, everyon, feel, about, the, clim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>[rt, didnt, catch, the, full, gopdeb, last, ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>[rt, no, mention, of, tamir, rice, and, the, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>[rt, that, carli, fiorina, is, trend, hour, af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>[rt, gopdeb, w, realdonaldtrump, deliv, the, h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0   Neutral  [rt, how, did, everyon, feel, about, the, clim...\n",
       "1  Positive  [rt, didnt, catch, the, full, gopdeb, last, ni...\n",
       "2   Neutral  [rt, no, mention, of, tamir, rice, and, the, g...\n",
       "3  Positive  [rt, that, carli, fiorina, is, trend, hour, af...\n",
       "4  Positive  [rt, gopdeb, w, realdonaldtrump, deliv, the, h..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## Up Next ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT', '@NancyLeeGrahn:', 'How', 'did', 'everyone', 'feel', 'about', 'the', 'Climate', 'Change', 'question', 'last', 'night?', 'Exactly.', '#GOPDebate']\n",
      "['RT', '@ScottWalker:', \"Didn't\", 'catch', 'the', 'full', '#GOPdebate', 'last', 'night.', 'Here', 'are', 'some', 'of', \"Scott's\", 'best', 'lines', 'in', '90', 'seconds.', '#Walker16', 'http://t.co/ZSfF‰Ы_']\n",
      "['RT', '@TJMShow:', 'No', 'mention', 'of', 'Tamir', 'Rice', 'and', 'the', '#GOPDebate', 'was', 'held', 'in', 'Cleveland?', 'Wow.']\n",
      "['RT', '@RobGeorge:', 'That', 'Carly', 'Fiorina', 'is', 'trending', '--', 'hours', 'after', 'HER', 'debate', '--', 'above', 'any', 'of', 'the', 'men', 'in', 'just-completed', '#GOPdebate', 'says', \"she's\", 'on', '‰Ы_']\n",
      "['RT', '@DanScavino:', '#GOPDebate', 'w/', '@realDonaldTrump', 'delivered', 'the', 'highest', 'ratings', 'in', 'the', 'history', 'of', 'presidential', 'debates.', '#Trump2016', 'http://t.co‰Ы_']\n"
     ]
    }
   ],
   "source": [
    "for i in df[:5].text:\n",
    "    print(i.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
